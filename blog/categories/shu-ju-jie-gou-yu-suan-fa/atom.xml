<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: 数据结构与算法 | 锡安之路]]></title>
  <link href="http://peterchen.cn/blog/categories/shu-ju-jie-gou-yu-suan-fa/atom.xml" rel="self"/>
  <link href="http://peterchen.cn/"/>
  <updated>2016-03-10T22:10:43+08:00</updated>
  <id>http://peterchen.cn/</id>
  <author>
    <name><![CDATA[陈浩（Peter）]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[A*算法优化]]></title>
    <link href="http://peterchen.cn/blog/2016/03/10/a-star-suan-fa-you-hua/"/>
    <updated>2016-03-10T22:02:44+08:00</updated>
    <id>http://peterchen.cn/blog/2016/03/10/a-star-suan-fa-you-hua</id>
    <content type="html"><![CDATA[<h1>一. 概述</h1>

<p>A算法是游戏中路径搜索的常见算法。Dijkstra是最短路径的经典算法，A算法的思路基本上和Dijkstra算法一致，在Dijkstra算法的基础上增加了启发函数，也就是：</p>

<p><strong><em>f(n) = g(n) + h(n)</em></strong></p>

<p>其中，n是路径上某一点，g(n)是从出发点到该点的cost，h(n)是关于该点的启发函数，通常是对从该点到目标花费的一个估计，例如到目标的直线距离或者曼哈顿距离。 <br/>
A算法每次选择f(n)最小的点，然后更新所有g(n)。 <br/>
如果你明白Dijkstra算法，那么在这里h(n) = 0 的话，A算法就和Dijkstra算法一样了。 <br/>
<br>
本文不详细讲解A算法，需要详细了解A算法的具体过程的，参见以下两篇文章： <br/>
<a href="http://www.cnblogs.com/kanego/archive/2011/08/30/2159070.html">理解A*算法的具体过程</a><br/>
<a href="http://www.cnblogs.com/technology/archive/2011/05/26/2058842.html">A*算法详解</a></p>

<h1>二. A*算法的优化思路</h1>

<p>A*算法优化的关键在于h(n)的选择。
一个启发函数h(n)被称为admissible的，是指h(n)的估计，不会超过节点N到目标的实际花费。</p>

<p>如果h(x)满足以下条件，h(x)被称为单调的(monotone, or consistent)。<br/>
对于任意一条边(x,y),<br/>
 <strong><em>h(x) &lt;= d(x,y) + h(y)</em></strong> <br/>
 其中d(x,y)是（x,y）的长度</p>

<p>如果满足这个条件，就意味着没有任何节点需要被处理多次，也就是说，在Dijkstra算法中，新加入一个节点会导致已添加节点中cost降低的情况不会存在，也就不需要去更新已添加节点(称为close set)。</p>

<p>如果一个启发函数是单调的，那么该启发函数一定是admissible的。如果该启发函数是admissible的，那么可以证明A*在同类算法中搜寻到最短的路径。</p>

<p>问题出在这里：如果我们更在意的是搜索的时间空间花费，而不是最优结果，那么A*算法就有优化空间。所以我们放松要求，修改我们的启发函数，使得我们搜寻到的路径不会比最佳路径差太多，就是优化算法，称为ε-admissible算法.</p>

<p>有多种ε-admissible算法，在此只举例最简单直接的一种： 加权A*(静态加权)算法。<br/>
假如ha(n)是一个admissible的启发函数，我们选取新的启发函数hw(n) = ε ha(n)，其中ε>1 作为启发函数。就可以在某种程度上进行优化。
下图1是使用ha(n)作为启发式算法，下图2是使用hw(n)作为启发式算法，其中ε取5.</p>

<p>图1：ha(x)作为启发算法 <br/>
图2：hn(x)作为启发算法</p>

<p>可以看出，ha(n)可以找到最小路径，但是多了许多无用的搜索；而hw(n)找到的不是最优路径，但是减少了大量无用搜索。</p>

<p>其他的优化算法思路类似都是在于启发函数的选择。详见参考文献。</p>

<p>参考：
<a href="https://en.wikipedia.org/wiki/A*_search_algorithm#Admissibility_and_optimality">https://en.wikipedia.org/wiki/A*_search_algorithm#Admissibility_and_optimality</a>
<a href="https://en.wikipedia.org/wiki/Consistent_heuristic">https://en.wikipedia.org/wiki/Consistent_heuristic</a></p>
]]></content>
  </entry>
  
</feed>
